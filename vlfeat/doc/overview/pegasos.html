<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <!-- Favicon -->
  <link href="../images/vl_blue.ico" type="image/x-icon" rel="icon"></link>
  <link href="../images/vl_blue.ico" type="image/x-icon" rel="shortcut icon"></link>

  <!-- Stylesheets -->
  <link href="../web.css" type="text/css" rel="stylesheet"></link>
  <link href="../pygmentize.css" type="text/css" rel="stylesheet"></link>
  <title>VLFeat - Tutorials - Pegasos</title>
  

  <!-- Scripts-->
  

  <!-- Google Custom Search -->
  <script xml:space="preserve">
    (function() {
    var cx = '003215582122030917471:oq23albfeam';
    var gcse = document.createElement('script'); gcse.type = 'text/javascript'; gcse.async = true;
    gcse.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') +
    '//www.google.com/cse/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(gcse, s);
    })();
  </script>

  <!-- Google Analytics -->
  <script xml:space="preserve" type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-4936091-2']);
    _gaq.push(['_trackPageview']);
    (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>
 </head>

 <!-- Body Start -->
 <body>
  <div id="header">
   <!-- Google CSE Search Box -->
   <div id="google" class="gcse-searchbox-only" data-resultsUrl="http://www.vlfeat.org/search.html"></div>
   <h1><a shape="rect" href="../index.html" class="plain"><span id="vlfeat">VLFeat</span><span id="dotorg">.org</span></a></h1>
  </div>
  <div id="headbanner">
   Tutorials - Pegasos
  </div>
  <div id="pagebody">
   <div id="sidebar"> <!-- Navigation Start -->
    <ul>
<li><a href="../index.html">Home</a>
</li>
<li><a href="../download.html">Download</a>
</li>
<li><a href="../doc.html">Documentation</a>
</li>
<li><a href="tut.html">Tutorials</a>
<ul>
<li><a href="covdet.html">Covdet</a>
</li>
<li><a href="hog.html">HOG</a>
</li>
<li><a href="sift.html">SIFT</a>
</li>
<li><a href="dsift.html">DSIFT/PHOW</a>
</li>
<li><a href="mser.html">MSER</a>
</li>
<li><a href="ikm.html">IKM</a>
</li>
<li><a href="hikm.html">HIKM</a>
</li>
<li><a href="aib.html">AIB</a>
</li>
<li><a href="quickshift.html">Quick shift</a>
</li>
<li><a href="slic.html">SLIC</a>
</li>
<li><a href="kdtree.html">kd-tree</a>
</li>
<li><a href="imdisttf.html">Distance transf.</a>
</li>
<li><a href="utils.html">Utils</a>
</li>
<li><a href="pegasos.html#tut.pegasos" class='active' >Pegasos</a>
</li>
<li><a href="plots-rank.html">Plots: rank</a>
</li>
</ul></li>
<li><a href="../applications/apps.html">Applications</a>
</li>
</ul>

   </div> <!-- sidebar -->
   <div id="content">
     

<p><b>VLFeat</b> includes a fast SVM solver, called 
<code>vl_svmpegasos</code>. The function implements the Pegasos SVM 
algorithm <a shape="rect" href="#ref1">[1]</a>, with a few adds such online 
Homogeneous kernel map expansion and SVM online statistics. </p> 

<!-- <p>Pegasos SVM <a href="#ref1">[1]</a> is implemented in <b>VLFeat</b> -->
<!--   by the function  <code>vl_svmpegasos</code>. Compared to the -->
<!--   original formulation, this implementation has some extras -->
<!--   features that allow memory efficiency and convergence analysis.</p> -->

<!-- <p>The use of online homogeneous kernel map<a href="#ref2">[2]</a> extensions reduces the  -->
<!--   memory usage up to the order of <i>n</i>, where <i>n</i> is the period of -->
<!--   the map. </p> -->

<!-- <p>In many  applications it is not clear which parameters and maps give -->
<!--   the best result, and one has to find the best setting via a series -->
<!--   of trials. <code>vl_svmpegasos</code> makes this process easier, -->
<!--   offering the possibility to check a set of statistics during the SVM -->
<!--   learning. </p> -->

<!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->
<h1 id="tut.pegasos">Pegasos SVM</h1>
<!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->



<p>A simple example on how to use <code>vl_svmpegasos</code> is presented below. Let's first build the training data  </p>
<div class="highlight"><pre><span class="c">% Set up training data</span>
<span class="n">Np</span> <span class="p">=</span> 200 <span class="p">;</span>
<span class="n">Nn</span> <span class="p">=</span> 200 <span class="p">;</span>

<span class="n">Xp</span> <span class="p">=</span> <span class="nb">diag</span><span class="p">([</span>1 3<span class="p">])</span><span class="o">*</span><span class="nb">randn</span><span class="p">(</span>2<span class="p">,</span> <span class="n">Np</span><span class="p">)</span> <span class="p">;</span>
<span class="n">Xn</span> <span class="p">=</span> <span class="nb">diag</span><span class="p">([</span>1 3<span class="p">])</span><span class="o">*</span><span class="nb">randn</span><span class="p">(</span>2<span class="p">,</span> <span class="n">Nn</span><span class="p">)</span> <span class="p">;</span>
<span class="n">Xp</span><span class="p">(</span>1<span class="p">,:)</span> <span class="p">=</span> <span class="n">Xp</span><span class="p">(</span>1<span class="p">,:)</span> <span class="o">+</span> 2  <span class="p">;</span>
<span class="n">Xn</span><span class="p">(</span>1<span class="p">,:)</span> <span class="p">=</span> <span class="n">Xn</span><span class="p">(</span>1<span class="p">,:)</span> <span class="o">-</span> 2  <span class="p">;</span>

<span class="n">X</span> <span class="p">=</span> <span class="p">[</span><span class="n">Xp</span> <span class="n">Xn</span><span class="p">]</span> <span class="p">;</span>
<span class="n">y</span> <span class="p">=</span> <span class="p">[</span><span class="nb">ones</span><span class="p">(</span>1<span class="p">,</span><span class="n">Np</span><span class="p">)</span> <span class="o">-</span><span class="nb">ones</span><span class="p">(</span>1<span class="p">,</span><span class="n">Nn</span><span class="p">)]</span> <span class="p">;</span>
</pre></div>

<p>Plotting <i>X</i> and <i>y</i> we have </p>
<div class="figure">
 <img src="../demo/pegasos_training.jpg"></img>
 <div class="caption">
  <span class="content">
   Training Data.
  </span>
 </div>
</div>

<p>Learning a linear classifier can be easily done with the following 2
lines of code:</p>

<div class="highlight"><pre><span class="n">dataset</span> <span class="p">=</span> <span class="n">vl_maketrainingset</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">int8</span><span class="p">(</span><span class="n">y</span><span class="p">))</span> <span class="p">;</span>
<span class="p">[</span><span class="n">w</span> <span class="n">b</span> <span class="n">info</span><span class="p">]</span> <span class="p">=</span> <span class="n">vl_svmpegasos</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> 0<span class="p">.</span>01<span class="p">,</span> <span class="p">...</span>
                           <span class="s">&#39;MaxIterations&#39;</span><span class="p">,</span>5000<span class="p">)</span> <span class="p">;</span>
</pre></div>


<p>where we first create a struct containing the training data
using  <code>vl_maketraining data</code> and then we call the the SVM
solver. The output model <code>w</code> is plotted over the training
  data in the following figure. </p>

<div class="figure">
 <img src="../demo/pegasos_res.jpg"></img>
 <div class="caption">
  <span class="content">
   Learned model.
  </span>
 </div>
</div>

<p> The output <code>b</code> is equal to <code>0</code> since the
  training data admits an SVM model passing from the origins. </p>

<p> The output <code>info</code> is a struct containing some
  statistic on the learned SVM: </p>


<div class="highlight"><pre><span class="n">info</span> <span class="p">=</span> 

           <span class="n">dimension</span><span class="p">:</span> 2
          <span class="n">iterations</span><span class="p">:</span> 5000
       <span class="n">maxIterations</span><span class="p">:</span> 5000
             <span class="n">epsilon</span><span class="p">:</span> <span class="o">-</span>1
              <span class="n">lambda</span><span class="p">:</span> 0<span class="p">.</span>0100
      <span class="n">biasMultiplier</span><span class="p">:</span> 0
    <span class="n">biasLearningRate</span><span class="p">:</span> 1
     <span class="n">energyFrequency</span><span class="p">:</span> 100
         <span class="n">elapsedTime</span><span class="p">:</span> 0<span class="p">.</span>0022
              <span class="n">energy</span><span class="p">:</span> 0<span class="p">.</span>1727
     <span class="n">regularizerTerm</span><span class="p">:</span> 0<span class="p">.</span>0168
             <span class="n">lossPos</span><span class="p">:</span> 0<span class="p">.</span>1003
             <span class="n">lossNeg</span><span class="p">:</span> 0<span class="p">.</span>0556
         <span class="n">hardLossPos</span><span class="p">:</span> 0<span class="p">.</span>1050
         <span class="n">hardLossNeg</span><span class="p">:</span> 0<span class="p">.</span>0750
</pre></div>


<p>It is also possible to  use under some
  assumptions<a shape="rect" href="#ref2">[2]</a> an homogeneous kernel map expanded online inside the
  solver. This can be done with the following command:  </p>

<div class="highlight"><pre><span class="n">dataset</span> <span class="p">=</span> <span class="n">vl_maketrainingset</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">int8</span><span class="p">(</span><span class="n">y</span><span class="p">).</span><span class="s">&#39;homkermap&#39;</span><span class="p">,</span>2<span class="p">,</span><span class="s">&#39;KChi2&#39;</span><span class="p">)</span> <span class="p">;</span>
</pre></div>


<p>The above code creates a training set without applying any
  homogeneous kernel map to the data. When the solver is called  it will expand each data point with a Chi Squared kernel
  of period 2.</p>

<!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->
<h1 id="tut.pegasos.diagn">Real-time diagnostics</h1>
<!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->

<p>VLFeat allows to get statistics during the training process. It is
  sufficient to pass a function handle to the solver. The function
  will be then called every <code>energyFrequency</code> time.</p>

<p>The following function simply plots the SVM energy values for all
  the past iterations: </p>

<div class="highlight"><pre><span class="k">function</span><span class="w"> </span>energy <span class="p">=</span><span class="w"> </span><span class="nf">diagnostics</span><span class="p">(</span>svm,energy<span class="p">)</span><span class="w"></span>
<span class="w">  </span><span class="n">figure</span><span class="p">(</span>2<span class="p">)</span> <span class="p">;</span> 
  <span class="n">energy</span> <span class="p">=</span> <span class="p">[</span><span class="n">energy</span> <span class="n">svm</span><span class="p">.</span><span class="n">energy</span><span class="p">]</span> <span class="p">;</span>
  <span class="n">plot</span><span class="p">(</span><span class="n">energy</span><span class="p">)</span> <span class="p">;</span>
  <span class="n">drawnow</span> <span class="p">;</span>
</pre></div>


<p>The energy value for the past iterations are kept in the
  row vector <code>energy</code>. The following code produces a plot of the energy value in real-time during the learning process. </p>

<div class="highlight"><pre><span class="n">energy</span> <span class="p">=</span> <span class="p">[]</span> <span class="p">;</span>
<span class="n">dataset</span> <span class="p">=</span> <span class="n">vl_maketrainingset</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">int8</span><span class="p">(</span><span class="n">y</span><span class="p">))</span> <span class="p">;</span>
<span class="p">[</span><span class="n">w</span> <span class="n">b</span> <span class="n">info</span><span class="p">]</span> <span class="p">=</span> <span class="n">vl_svmpegasos</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">lambda</span><span class="p">,</span> <span class="p">...</span>
                           <span class="s">&#39;MaxIterations&#39;</span><span class="p">,</span>5000<span class="p">,...</span>
                           <span class="s">&#39;DiagnosticFunction&#39;</span><span class="p">,@</span><span class="n">diagnostics</span><span class="p">,...</span>
                           <span class="s">&#39;DiagnosticCallRef&#39;</span><span class="p">,</span><span class="n">energy</span><span class="p">)</span> <span class="p">;</span>
</pre></div>


<div class="figure">
 <img src="../demo/pegasos_energy.jpg"></img>
 <div class="caption">
  <span class="content">
   SVM real-time energy values plot.
  </span>
 </div>
</div>
<!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->
<h1 id="tut.dsift.references">References</h1>
<!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->

<ul>
  <li id="ref1">[1] Y. Singer and N. Srebro <em>Pegasos: Primal
  estimated sub-gradient solver for SVM</em> In Proc. ICML,
  2007.
</li>
<li id="ref2">[2] A. Vedaldi and A. Zisserman. <em>Efficient additive
    kernels via explicit feature maps</em>. In PAMI, 2011. 
</li>
</ul>


   </div>
   <div class="clear">&nbsp;</div>
  </div> <!-- pagebody -->
  <div id="footer">
   &copy; 2007-12 The VLFeat Authors
  </div> <!-- footer -->
 </body>
 <!-- Body ends -->
</html>

 